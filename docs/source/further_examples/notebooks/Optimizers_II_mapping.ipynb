{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b827504d",
   "metadata": {},
   "source": [
    "# Paralelization for gradient-free optimizers: Differential Evolution\n",
    "In this notebook, a more complex example is aimed. Here, a differential evolution optimization will be performed employing the vQPUs as accelerators of the quantum task of which the parameters are updated.\n",
    "\n",
    "As in the rest of the examples, all the imports are done and the vQPUs are raised. After this, they are brought to the program workflow in form of `QPU` instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c532632a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested QPUs with command:\n",
      "\tqraise -n 10 -t 00:20:00 --simulator=Aer --co-located\n",
      "QPUs ready to work âœ…\n",
      "QPU 377561_2384905, backend: SimpleBackend, simulator: AerSimulator, version: 0.0.1.\n",
      "QPU 377561_2384906, backend: SimpleBackend, simulator: AerSimulator, version: 0.0.1.\n",
      "QPU 377561_2384907, backend: SimpleBackend, simulator: AerSimulator, version: 0.0.1.\n",
      "QPU 377561_2384908, backend: SimpleBackend, simulator: AerSimulator, version: 0.0.1.\n",
      "QPU 377561_2384909, backend: SimpleBackend, simulator: AerSimulator, version: 0.0.1.\n",
      "QPU 377561_2384910, backend: SimpleBackend, simulator: AerSimulator, version: 0.0.1.\n",
      "QPU 377561_2384911, backend: SimpleBackend, simulator: AerSimulator, version: 0.0.1.\n",
      "QPU 377561_2384912, backend: SimpleBackend, simulator: AerSimulator, version: 0.0.1.\n",
      "QPU 377561_2384913, backend: SimpleBackend, simulator: AerSimulator, version: 0.0.1.\n",
      "QPU 377561_2384914, backend: SimpleBackend, simulator: AerSimulator, version: 0.0.1.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from scipy.stats import entropy, norm\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "sys.path.append(os.getenv(\"HOME\"))\n",
    "\n",
    "from cunqa.circuit import CunqaCircuit\n",
    "from cunqa import get_QPUs, qraise, qdrop\n",
    "from cunqa.qpu import run \n",
    "from cunqa.mappers import QJobMapper, QPUCircuitMapper\n",
    "\n",
    "family = qraise(10, \"00:20:00\", simulator = \"Aer\",  co_located = True)\n",
    "qpus  = get_QPUs(co_located = True, family = family)\n",
    "\n",
    "for q in qpus:\n",
    "    print(f\"QPU {q.id}, backend: {q.backend['name']}, simulator: {q.backend['simulator']}, version: {q.backend['version']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f94f9",
   "metadata": {},
   "source": [
    "In this example, the same ansatz, target distribution and distribution divergence measure is defined as in the parameters update feature example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "723a8b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardware_efficient_ansatz(num_qubits, num_layers):\n",
    "    qc = CunqaCircuit(num_qubits)\n",
    "    for p_id in range(num_layers):\n",
    "        for qubit in range(num_qubits):\n",
    "            qc.ry(f\"phi_{p_id}_{qubit}\", qubit)\n",
    "            qc.rz(f\"lam_{p_id}_{qubit}\", qubit)\n",
    "        for qubit in range(num_qubits - 1):\n",
    "            qc.cx(qubit, qubit + 1)\n",
    "    qc.measure_all()\n",
    "    return qc\n",
    "\n",
    "def target_distribution(num_qubits):\n",
    "    # Define a normal distribution over the states\n",
    "    num_states = 2 ** num_qubits\n",
    "    states = np.arange(num_states)\n",
    "    mean = num_states / 2\n",
    "    std_dev = num_states / 4\n",
    "    target_probs = norm.pdf(states, mean, std_dev)\n",
    "    target_probs /= target_probs.sum()  # Normalize to make it a valid probability distribution\n",
    "    target_dist = {format(i, f'0{num_qubits}b'): target_probs[i] for i in range(num_states)}\n",
    "    return target_dist\n",
    "\n",
    "def KL_divergence(counts, n_shots, target_dist):\n",
    "    # Convert counts to probabilities\n",
    "    pdf = pd.DataFrame.from_dict(counts, orient=\"index\").reset_index()\n",
    "    pdf.rename(columns={\"index\": \"state\", 0: \"counts\"}, inplace=True)\n",
    "    pdf[\"probability\"] = pdf[\"counts\"] / n_shots\n",
    "    \n",
    "    # Create a dictionary for the obtained distribution\n",
    "    obtained_dist = pdf.set_index(\"state\")[\"probability\"].to_dict()\n",
    "    \n",
    "    # Ensure all states are present in the obtained distribution\n",
    "    for state in target_dist:\n",
    "        if state not in obtained_dist:\n",
    "            obtained_dist[state] = 0.0\n",
    "    \n",
    "    # Convert distributions to lists for KL divergence calculation\n",
    "    target_probs = [target_dist[state] for state in sorted(target_dist)]\n",
    "    obtained_probs = [obtained_dist[state] for state in sorted(obtained_dist)]\n",
    "    \n",
    "    # Calculate KL divergence\n",
    "    kl_divergence = entropy(obtained_probs, target_probs)\n",
    "    \n",
    "    return kl_divergence\n",
    "\n",
    "num_qubits = 6\n",
    "num_layers = 3\n",
    "ansatz = hardware_efficient_ansatz(num_qubits, num_layers)\n",
    "num_params = 2 * num_qubits * num_layers\n",
    "\n",
    "pop = [\n",
    "    [random.uniform(-math.pi, math.pi) for _ in range(num_params)]\n",
    "    for _ in range(num_params)\n",
    "]\n",
    "bounds=[(-np.pi,np.pi) for _ in range(num_params)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20e9a95-dd53-48a6-bd12-27775bc8ee55",
   "metadata": {},
   "source": [
    "What changes is the cost function, that in this case will be the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2118dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(result):\n",
    "    target_dist = target_distribution(num_qubits)\n",
    "    counts = result.counts\n",
    "    \n",
    "    return KL_divergence(counts, 1000, target_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ecb50-d796-48c7-939e-24c396b7f9f1",
   "metadata": {},
   "source": [
    "Now, similar to the previous example, a `make_callback` function is defined in order to generate a callback function tailored to the mapper employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e89e8e8-2d80-4f4c-ae18-bba1fad6dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_callback(mapper):\n",
    "    i = 0\n",
    "    \n",
    "    best_individual = []\n",
    "    energies = []\n",
    "    def callback(xk, convergence = 1e-8):\n",
    "        nonlocal i\n",
    "        best_individual.append(xk)\n",
    "        energy = mapper(cost_function, [xk])[0]\n",
    "        energies.append(energy)\n",
    "        i += 1\n",
    "\n",
    "    return callback, energies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0629a4c6",
   "metadata": {},
   "source": [
    "## QJobMapper\n",
    "After all the previous steps, the optimization is ready to be performed. In this case, the mapper employed will be `QJobMapper`. This mapper takes a set of `QJobs` and uses the parameter update feature in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d6e57f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n",
      "\u001b[33m\twarning: [qjob.py] You have not obtained the previous results. They will be discarded.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "init_qjobs = []\n",
    "for i in range(1 * num_params): # we set pop=1 as the population size is pop*num_params\n",
    "    qpu = qpus[i%len(qpus)] # we select the qpu\n",
    "    init_qjobs.append(run(ansatz, qpu, [0.0 for _ in range(num_params)], shots=1000))\n",
    "\n",
    "mapper = QJobMapper(init_qjobs)\n",
    "\n",
    "callback1, energies1 = make_callback(mapper)\n",
    "result1 = differential_evolution(cost_function, \n",
    "                                bounds, \n",
    "                                maxiter = 1000, \n",
    "                                workers = mapper, \n",
    "                                updating = 'deferred',\n",
    "                                strategy = 'best1bin',\n",
    "                                init = pop, \n",
    "                                polish = False, \n",
    "                                callback=callback1\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de3f29a4-162f-45d8-9c70-06edfd4a886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             message: Maximum number of iterations has been exceeded.\n",
      "             success: False\n",
      "                 fun: 0.20667795823664736\n",
      "                   x: [-1.802e-01 -1.348e+00 ... -1.992e+00  3.043e-01]\n",
      "                 nit: 1000\n",
      "                nfev: 36036\n",
      "          population: [[-1.802e-01 -1.348e+00 ... -1.992e+00  3.043e-01]\n",
      "                       [ 1.073e+00 -1.708e+00 ... -1.075e+00  9.150e-01]\n",
      "                       ...\n",
      "                       [ 1.922e+00  7.773e-01 ... -1.187e+00 -1.805e+00]\n",
      "                       [-7.132e-01  4.087e-01 ... -1.815e+00  2.353e-01]]\n",
      " population_energies: [ 2.067e-01  2.392e-01 ...  2.599e-01  2.871e-01]\n"
     ]
    }
   ],
   "source": [
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd7a7e6",
   "metadata": {},
   "source": [
    "## QPUCircuitMapper\n",
    "In this case, instead of using the parameter update feature, it creates a circuit each time the mapper is called. But, as it can be seen, the employment of this mapper and the previous one is analogous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b08cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = QPUCircuitMapper(qpus, ansatz, shots=1000)\n",
    "\n",
    "callback2, energies2 = make_callback(mapper)\n",
    "result2 = differential_evolution(cost_function, \n",
    "                                bounds, \n",
    "                                maxiter = 1000, \n",
    "                                workers = mapper, \n",
    "                                updating = 'deferred',\n",
    "                                strategy = 'best1bin', \n",
    "                                init = pop, \n",
    "                                polish = False, \n",
    "                                callback=callback2\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdeb42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a35a95-de53-4cc3-80b5-e8ab5a5d0ceb",
   "metadata": {},
   "source": [
    "### Comparison between QJobMapper and QPUCircuitMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaf8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.clf()\n",
    "plt.plot(np.linspace(0, result1.nit, result1.nit), energies1, label=\"Optimization path (QJobMapper)\")\n",
    "upper_bound = result1.nit\n",
    "plt.plot(np.linspace(0, result2.nit, result2.nit), energies2, label=\"Optimization path (QPUCircuitMapper)\")\n",
    "plt.plot(np.linspace(0, upper_bound, upper_bound), np.zeros(upper_bound), \"--\", label=\"Target cost\")\n",
    "plt.xlabel(\"Step\"); plt.ylabel(\"Cost\");\n",
    "plt.legend(loc=\"upper right\");\n",
    "plt.title(f\"n = {num_qubits}, l = {num_layers}, # params = {num_params}\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "qdrop(family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75d387d-eb7d-4998-8cce-c27cccd32dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9030814-d1ff-408b-aee2-45247e26dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Paralelization of expectation value terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff7f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Paralelization for gradient optimizers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
