{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c532632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "# path to access c++ files\n",
    "installation_path = os.getenv(\"INSTALL_PATH\")\n",
    "sys.path.append(installation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d0c54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QPU 0, backend: BasicAer, simulator: AerSimulator, version: 0.0.1.\n",
      "QPU 1, backend: BasicAer, simulator: AerSimulator, version: 0.0.1.\n",
      "QPU 2, backend: BasicAer, simulator: AerSimulator, version: 0.0.1.\n",
      "QPU 3, backend: BasicAer, simulator: AerSimulator, version: 0.0.1.\n"
     ]
    }
   ],
   "source": [
    "from cunqa.qpu import getQPUs\n",
    "\n",
    "qpus  = getQPUs()\n",
    "\n",
    "for q in qpus:\n",
    "    print(f\"QPU {q.id}, backend: {q.backend.name}, simulator: {q.backend.simulator}, version: {q.backend.version}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db7e8c6",
   "metadata": {},
   "source": [
    "# Examples for optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa81e1",
   "metadata": {},
   "source": [
    "Before sending a circuit to the QClient, a transpilation process occurs (if not, it is done by the user). This process, in some cases, can take much time and resources, as well as sending it. If we were to execute a single circuit, it shouldn´t be a big problem, but it is when it comes to variational algorithms.\n",
    "\n",
    "This quantum-classical algorithms require several executions of the same circuit but changing the value of the parameters, which are optimized in the classical part. In order to optimize this, we developed a functionallity that allows the user to upgrade the circuit parameters with no extra transpilations of the circuit, sending to the `QClient` the list of the parameters **ONLY**. This is of much advantage to speed up the computation in the cases in which transpilation takes a significant part of the total time of the simulation.\n",
    "\n",
    "Let´s see how to work with tis feature taking as an example a _Variational Quantum Algorithm_ for state preparation.\n",
    "\n",
    "We start from a _Hardware Efficient Ansatz_ to build our parametrized circuit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a68703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter\n",
    "\n",
    "def hardware_efficient_ansatz(num_qubits, num_layers):\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    param_idx = 0\n",
    "    for _ in range(num_layers):\n",
    "        for qubit in range(num_qubits):\n",
    "            phi = Parameter(f'phi_{param_idx}_{qubit}')\n",
    "            lam = Parameter(f'lam_{param_idx}_{qubit}')\n",
    "            qc.ry(phi, qubit)\n",
    "            qc.rz(lam, qubit)\n",
    "        param_idx += 1\n",
    "        for qubit in range(num_qubits - 1):\n",
    "            qc.cx(qubit, qubit + 1)\n",
    "    qc.measure_all()\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9f1aa6",
   "metadata": {},
   "source": [
    "The we need a cost function. We will define a target distribution and measure how far we are from it. We choose to prepare a normal distribution among all the $2^n$ possible outcomes of the circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e4b9c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_distribution(num_qubits):\n",
    "    # Define a normal distribution over the states\n",
    "    num_states = 2 ** num_qubits\n",
    "    states = np.arange(num_states)\n",
    "    mean = num_states / 2\n",
    "    std_dev = num_states / 4\n",
    "    target_probs = norm.pdf(states, mean, std_dev)\n",
    "    target_probs /= target_probs.sum()  # Normalize to make it a valid probability distribution\n",
    "    target_dist = {format(i, f'0{num_qubits}b'): target_probs[i] for i in range(num_states)}\n",
    "    return target_dist\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy, norm\n",
    "\n",
    "def KL_divergence(counts, n_shots, target_dist):\n",
    "    # Convert counts to probabilities\n",
    "    pdf = pd.DataFrame.from_dict(counts, orient=\"index\").reset_index()\n",
    "    pdf.rename(columns={\"index\": \"state\", 0: \"counts\"}, inplace=True)\n",
    "    pdf[\"probability\"] = pdf[\"counts\"] / n_shots\n",
    "    \n",
    "    # Create a dictionary for the obtained distribution\n",
    "    obtained_dist = pdf.set_index(\"state\")[\"probability\"].to_dict()\n",
    "    \n",
    "    # Ensure all states are present in the obtained distribution\n",
    "    for state in target_dist:\n",
    "        if state not in obtained_dist:\n",
    "            obtained_dist[state] = 0.0\n",
    "    \n",
    "    # Convert distributions to lists for KL divergence calculation\n",
    "    target_probs = [target_dist[state] for state in sorted(target_dist)]\n",
    "    obtained_probs = [obtained_dist[state] for state in sorted(obtained_dist)]\n",
    "    \n",
    "    # Calculate KL divergence\n",
    "    kl_divergence = entropy(obtained_probs, target_probs)\n",
    "    \n",
    "    return kl_divergence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c74e1438",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 6\n",
    "\n",
    "num_layers = 3\n",
    "\n",
    "n_shots = 1e5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23f13db",
   "metadata": {},
   "source": [
    "### Simply using the `QPU.run()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa26a3eb",
   "metadata": {},
   "source": [
    "At first we should try the intiutive alternative: upgrading parameters at the QClient, transpiling and sending the whole circuit to the QPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5398907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function_run(params):\n",
    "    n_shots = 1e5\n",
    "    target_dist = target_distribution(num_qubits)\n",
    "    \n",
    "    circuit = ansatz.assign_parameters(params)\n",
    "    \n",
    "    result = qpu.run(circuit, transpile = True, opt_level = 0, shots = n_shots).result()\n",
    "    \n",
    "    counts = result.get_counts()\n",
    "    \n",
    "    return KL_divergence(counts, n_shots, target_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ec8a31",
   "metadata": {},
   "source": [
    "Our cost function updates the parameters given by the optimizer, asigns them to the ansatz and sends the circuit with the transpilation option set `True`. Let´s choose a QPU to work with and go ahead with the optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e2d80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "qpu = qpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "052a5b83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration step 0: f(x) = 5.644885693319627\n",
      "Iteration step 20: f(x) = 3.245480781685051\n",
      "Iteration step 40: f(x) = 0.6972965249135434\n",
      "Iteration step 60: f(x) = 0.5185828042150522\n",
      "Iteration step 80: f(x) = 0.4418296545294022\n",
      "Iteration step 100: f(x) = 0.383193817799311\n",
      "Iteration step 120: f(x) = 0.2852119732374594\n",
      "Iteration step 140: f(x) = 0.22407828566916113\n",
      "Iteration step 160: f(x) = 0.19947657662099116\n",
      "Iteration step 180: f(x) = 0.16231180010780616\n",
      "Iteration step 200: f(x) = 0.14044092401230052\n",
      "Iteration step 220: f(x) = 0.11611477804691706\n",
      "Iteration step 240: f(x) = 0.09808601299159375\n",
      "Iteration step 260: f(x) = 0.09633662402782245\n",
      "Iteration step 280: f(x) = 0.09322929942134855\n",
      "Iteration step 300: f(x) = 0.06925961016695864\n",
      "Iteration step 320: f(x) = 0.064411766686984\n",
      "Iteration step 340: f(x) = 0.06275018045624231\n",
      "Iteration step 360: f(x) = 0.057339376543276796\n",
      "Iteration step 380: f(x) = 0.05297885747565084\n",
      "Iteration step 400: f(x) = 0.053056842400203\n",
      "Iteration step 420: f(x) = 0.04940963792091114\n",
      "Iteration step 440: f(x) = 0.0479882245160259\n",
      "Iteration step 460: f(x) = 0.04673495197856461\n",
      "Iteration step 480: f(x) = 0.04813605862123327\n",
      "Iteration step 500: f(x) = 0.0473367904723431\n",
      "\n",
      "   Normal return from subroutine COBYLA\n",
      "\n",
      "   NFVALS =  520   F = 4.481425E-02    MAXCV = 0.000000E+00\n",
      "   X = 1.211105E-01   6.716594E-02   5.323316E-01   4.475626E-01   1.288005E+00\n",
      "       3.456120E-01  -4.850203E-01   3.210649E-01   1.979830E-01   2.955729E-01\n",
      "       3.490587E-01   1.021490E+00   3.445241E-01   3.056974E-01   1.417536E-01\n",
      "      -4.243419E-01  -6.234186E-01  -6.184072E-01   9.860183E-03   6.282236E-01\n",
      "       1.180287E+00   5.573598E-01   1.276009E+00   1.456130E+00   1.613316E+00\n",
      "      -3.013171E-01   7.816262E-01  -2.009880E-01   1.022751E+00  -1.474044E-01\n",
      "      -1.841018E-01   1.456823E+00   4.495584E-02   1.568966E+00  -3.415137E-01\n",
      "       1.587370E+00\n",
      "\n",
      "Total optimization time:  114.49694728851318  s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ansatz = hardware_efficient_ansatz(num_qubits, num_layers)\n",
    "\n",
    "num_parameters = ansatz.num_parameters\n",
    "\n",
    "initial_parameters = np.zeros(num_parameters)\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "i = 0\n",
    "\n",
    "cost_run = []\n",
    "individuals_run = []\n",
    "\n",
    "def callback(xk):\n",
    "    global i\n",
    "    e = cost_function_run(xk)\n",
    "    individuals_run.append(xk)\n",
    "    cost_run.append(e)\n",
    "    if i%20 == 0:\n",
    "        print(f\"Iteration step {i}: f(x) = {e}\")\n",
    "    i+=1\n",
    "\n",
    "tick = time.time()\n",
    "optimization_result_run = minimize(cost_function_run, initial_parameters, method='COBYLA',\n",
    "        callback=callback, tol = 0.01,\n",
    "        options={\n",
    "        'disp': True,     # Print info at the end\n",
    "        'maxiter': 4000   # Limit the number of iterations\n",
    "    })\n",
    "tack = time.time()\n",
    "time_run = tack-tick\n",
    "print()\n",
    "print(\"Total optimization time: \", time_run, \" s\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcc4cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "plt.plot(np.linspace(0, optimization_result_run.nfev, optimization_result_run.nfev), cost_run, label=\"Optimization path (run())\")\n",
    "upper_bound = optimization_result_run.nfev\n",
    "plt.plot(np.linspace(0, upper_bound, upper_bound), np.zeros(upper_bound), \"--\", label=\"Target cost\")\n",
    "plt.xlabel(\"Step\"); plt.ylabel(\"Cost\"); plt.legend(loc=\"upper right\"); plt.title(f\"n = {num_qubits}, l = {num_layers}, # params = {num_parameters}\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# plt.savefig(f\"optimization_run_n_{num_qubits}_p_{num_parameters}.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbc16b7",
   "metadata": {},
   "source": [
    "### Using `QJob.upgrade_parameters()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113393a",
   "metadata": {},
   "source": [
    "The first step now is to create the `qjob.QJob` object that which parameters we are going to upgrade in each step of the optimization; for that, we must run a circuit with initial parameters in a QPU, the procedure is as we explained above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d44dbc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz = hardware_efficient_ansatz(num_qubits, num_layers)\n",
    "\n",
    "num_parameters = ansatz.num_parameters\n",
    "\n",
    "initial_parameters = np.zeros(num_parameters)\n",
    "\n",
    "circuit = ansatz.assign_parameters(initial_parameters)\n",
    "\n",
    "qjob = qpu.run(circuit, transpile = True, opt_level = 0, shots = n_shots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90da639",
   "metadata": {},
   "source": [
    "Now that we have sent to the virtual QPU the transpiled circuit, we can use the method `qjob.QJob.upgrade_parameters()` to change the rotations of the gates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec54866c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result with initial_parameters: \n",
      "{'000000': 100000}\n",
      "\n",
      "Result with random_parameters: \n",
      "{'000000': 9386, '000001': 10, '010000': 2330, '010001': 119, '010010': 1181, '010011': 37, '010100': 5465, '010101': 28, '010110': 1095, '010111': 79, '011000': 334, '011001': 726, '011010': 261, '011011': 169, '011100': 7190, '011101': 102, '011110': 1409, '011111': 115, '000010': 3586, '100000': 4063, '100001': 39, '100010': 2108, '100011': 101, '100100': 1011, '100101': 346, '100110': 7954, '100111': 678, '101000': 543, '101001': 2, '101010': 365, '101011': 139, '101100': 419, '101101': 289, '101110': 1047, '101111': 660, '000011': 153, '110000': 222, '110001': 66, '110010': 945, '110011': 26, '110100': 12087, '110101': 16, '110110': 2787, '110111': 57, '111000': 336, '111001': 401, '111010': 404, '111011': 78, '111100': 13197, '111101': 56, '111110': 3902, '111111': 418, '000100': 1147, '000101': 201, '000110': 3609, '000111': 365, '001000': 1658, '001001': 77, '001010': 1521, '001011': 180, '001100': 988, '001101': 179, '001110': 1413, '001111': 125}\n"
     ]
    }
   ],
   "source": [
    "print(\"Result with initial_parameters: \")\n",
    "print(qjob.result().get_counts())\n",
    "\n",
    "random_parameters = np.random.uniform(0, 2 * np.pi, num_parameters).tolist()\n",
    "qjob.upgrade_parameters(random_parameters)\n",
    "\n",
    "print()\n",
    "print(\"Result with random_parameters: \")\n",
    "print(qjob.result().get_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada125fd",
   "metadata": {},
   "source": [
    "**Important considerations:**\n",
    "\n",
    "- The method acepts parameters in a `list`, if you have a `numpy.array`, simply apply `.tolist()` to transform it.\n",
    "\n",
    "- When sending the circuit and setting `transpile=True`, we should be carefull that the transpilation process doesn't condense gates and combine parameters, therefore, if the user wants `cunqa`to transpile, they must set `opt_level=0`.\n",
    "\n",
    "Note that `qjob.QJob.upgrade_parameters()` is a non-blocking call, as it was `qpu.QPU.run()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f430de",
   "metadata": {},
   "source": [
    "Now that we are familiar with the procedure, we can design a cost funtion that takes a set of parameters, upgrades the `qjob.QJob`, gets the result and calculates the divergence from the desired distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c416b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(params):\n",
    "    n_shots = 100000\n",
    "    target_dist = target_distribution(num_qubits)\n",
    "    \n",
    "    result = qjob.upgrade_parameters(params.tolist()).result()\n",
    "    \n",
    "    counts = result.get_counts()\n",
    "    \n",
    "    return KL_divergence(counts, n_shots, target_dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f3a056",
   "metadata": {},
   "source": [
    "Now we are ready to start our optimization. We will use `scipy.optimize` to minimize the divergence of our result distribution from the target one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f9016ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration step 0: f(x) = 4.811337612621281\n",
      "Iteration step 10: f(x) = 2.816376296043694\n",
      "Iteration step 20: f(x) = 1.232573687379987\n",
      "Iteration step 30: f(x) = 0.7495666335308395\n",
      "Iteration step 40: f(x) = 0.5238100939434385\n",
      "Iteration step 50: f(x) = 0.46673943842001264\n",
      "Iteration step 60: f(x) = 0.4192477282326038\n",
      "Iteration step 70: f(x) = 0.42673494245966354\n",
      "Iteration step 80: f(x) = 0.45760514198773866\n",
      "Iteration step 90: f(x) = 0.34695710096309407\n",
      "Iteration step 100: f(x) = 0.34665472830728583\n",
      "Iteration step 110: f(x) = 0.2398424135979927\n",
      "Iteration step 120: f(x) = 0.20602090701940476\n",
      "Iteration step 130: f(x) = 0.12764023227383642\n",
      "Iteration step 140: f(x) = 0.11967366695566399\n",
      "Iteration step 150: f(x) = 0.10130619466725205\n",
      "Iteration step 160: f(x) = 0.12201874078938921\n",
      "Iteration step 170: f(x) = 0.0904378975415473\n",
      "Iteration step 180: f(x) = 0.0688298911635222\n",
      "Iteration step 190: f(x) = 0.08073272147266089\n",
      "Iteration step 200: f(x) = 0.07069643633053219\n",
      "Iteration step 210: f(x) = 0.07035912679922633\n",
      "Iteration step 220: f(x) = 0.06321890741525685\n",
      "Iteration step 230: f(x) = 0.07260763844010887\n",
      "Iteration step 240: f(x) = 0.0610524377991109\n",
      "Iteration step 250: f(x) = 0.057540532412104425\n",
      "Iteration step 260: f(x) = 0.05251871860080467\n",
      "Iteration step 270: f(x) = 0.04762368251164078\n",
      "Iteration step 280: f(x) = 0.05044292851247499\n",
      "Iteration step 290: f(x) = 0.04386900710446344\n",
      "Iteration step 300: f(x) = 0.042522862344569805\n",
      "Iteration step 310: f(x) = 0.04359405756897527\n",
      "Iteration step 320: f(x) = 0.042623083660579306\n",
      "Iteration step 330: f(x) = 0.03783576349933694\n",
      "Iteration step 340: f(x) = 0.03935555636176006\n",
      "Iteration step 350: f(x) = 0.03901343011231287\n",
      "Iteration step 360: f(x) = 0.03860073514541997\n",
      "Iteration step 370: f(x) = 0.037451809693180904\n",
      "Iteration step 380: f(x) = 0.03952089202642195\n",
      "Iteration step 390: f(x) = 0.03896538485465507\n",
      "Iteration step 400: f(x) = 0.03878616564902021\n",
      "Iteration step 410: f(x) = 0.037449908651107415\n",
      "Iteration step 420: f(x) = 0.037056186057957824\n",
      "Iteration step 430: f(x) = 0.036446663101409586\n",
      "\n",
      "   Normal return from subroutine COBYLA\n",
      "\n",
      "Total optimization time:  91.51999545097351  s\n",
      "\n",
      "   NFVALS =  437   F = 3.488464E-02    MAXCV = 0.000000E+00\n",
      "   X = 1.291609E+00   3.647883E-01   6.327560E-01   2.960107E-01   5.313905E-01\n",
      "       9.498232E-01   1.421827E+00   1.019328E+00   4.984737E-01   3.609013E-02\n",
      "      -1.363604E-01   1.781941E+00   1.601889E+00   1.509603E+00   4.416077E-02\n",
      "       1.828978E+00   1.647693E+00  -2.624360E-01   7.518868E-01   5.244825E-03\n",
      "       8.335320E-01  -6.001098E-01  -5.048084E-02  -5.802934E-01   1.581256E+00\n",
      "       1.785228E+00   1.579211E+00   7.291039E-01   3.070070E-02  -2.985711E-01\n",
      "      -4.594686E-02  -4.670611E-02   3.559684E-01   9.338572E-01  -5.426107E-01\n",
      "      -1.370758E-02\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "import time\n",
    "\n",
    "i = 0\n",
    "\n",
    "initial_parameters = np.zeros(num_parameters)\n",
    "\n",
    "cost = []\n",
    "individuals = []\n",
    "\n",
    "def callback(xk):\n",
    "    global i\n",
    "    e = cost_function(xk)\n",
    "    individuals.append(xk)\n",
    "    cost.append(e)\n",
    "    if i%10 == 0:\n",
    "        print(f\"Iteration step {i}: f(x) = {e}\")\n",
    "    i+=1\n",
    "\n",
    "tick = time.time()\n",
    "optimization_result = minimize(cost_function, initial_parameters, method='COBYLA',\n",
    "        callback=callback, tol = 0.01,\n",
    "        options={\n",
    "        'disp': True,     # Print info during iterations\n",
    "        'maxiter': 4000     # Limit the number of iterations\n",
    "    })\n",
    "tack = time.time()\n",
    "time_up = tack-tick\n",
    "print()\n",
    "print(\"Total optimization time: \", time_up, \" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f8a67e",
   "metadata": {},
   "source": [
    "We can plot the evolution of the cost function during the optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f269cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "plt.plot(np.linspace(0, optimization_result.nfev, optimization_result.nfev), cost, label=\"Optimization path (upgrade_params())\")\n",
    "plt.plot(np.linspace(0, optimization_result_run.nfev, optimization_result_run.nfev), cost_run, label=\"Optimization path (run())\")\n",
    "upper_bound = max(optimization_result_run.nfev, optimization_result.nfev)\n",
    "plt.plot(np.linspace(0, upper_bound, upper_bound), np.zeros(upper_bound), \"--\", label=\"Target cost\")\n",
    "plt.xlabel(\"Step\"); plt.ylabel(\"Cost\"); plt.legend(loc=\"upper right\"); plt.title(f\"n = {num_qubits}, l = {num_layers}, # params = {num_parameters}\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# plt.savefig(f\"optimization_n_{num_qubits}_p_{num_parameters}.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ab7f9",
   "metadata": {},
   "source": [
    "# Paralelization of expectation value terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ff7f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1910dbed",
   "metadata": {},
   "source": [
    "# Paralelization for gradient optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b7dc77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827504d",
   "metadata": {},
   "source": [
    "# Paralelization for gradient-free optimizers: Differential Evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671d0d64",
   "metadata": {},
   "source": [
    "_Introduction and explanation_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f94f9",
   "metadata": {},
   "source": [
    "We recover the variational circuit used before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "723a8b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter\n",
    "\n",
    "def hardware_efficient_ansatz(num_qubits, num_layers):\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    param_idx = 0\n",
    "    for _ in range(num_layers):\n",
    "        for qubit in range(num_qubits):\n",
    "            phi = Parameter(f'phi_{param_idx}_{qubit}')\n",
    "            lam = Parameter(f'lam_{param_idx}_{qubit}')\n",
    "            qc.ry(phi, qubit)\n",
    "            qc.rz(lam, qubit)\n",
    "        param_idx += 1\n",
    "        for qubit in range(num_qubits - 1):\n",
    "            qc.cx(qubit, qubit + 1)\n",
    "    qc.measure_all()\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e95e1817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_distribution(num_qubits):\n",
    "    # Define a normal distribution over the states\n",
    "    num_states = 2 ** num_qubits\n",
    "    states = np.arange(num_states)\n",
    "    mean = num_states / 2\n",
    "    std_dev = num_states / 4\n",
    "    target_probs = norm.pdf(states, mean, std_dev)\n",
    "    target_probs /= target_probs.sum()  # Normalize to make it a valid probability distribution\n",
    "    target_dist = {format(i, f'0{num_qubits}b'): target_probs[i] for i in range(num_states)}\n",
    "    return target_dist\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy, norm\n",
    "\n",
    "def KL_divergence(counts, n_shots, target_dist):\n",
    "    # Convert counts to probabilities\n",
    "    pdf = pd.DataFrame.from_dict(counts, orient=\"index\").reset_index()\n",
    "    pdf.rename(columns={\"index\": \"state\", 0: \"counts\"}, inplace=True)\n",
    "    pdf[\"probability\"] = pdf[\"counts\"] / n_shots\n",
    "    \n",
    "    # Create a dictionary for the obtained distribution\n",
    "    obtained_dist = pdf.set_index(\"state\")[\"probability\"].to_dict()\n",
    "    \n",
    "    # Ensure all states are present in the obtained distribution\n",
    "    for state in target_dist:\n",
    "        if state not in obtained_dist:\n",
    "            obtained_dist[state] = 0.0\n",
    "    \n",
    "    # Convert distributions to lists for KL divergence calculation\n",
    "    target_probs = [target_dist[state] for state in sorted(target_dist)]\n",
    "    obtained_probs = [obtained_dist[state] for state in sorted(obtained_dist)]\n",
    "    \n",
    "    # Calculate KL divergence\n",
    "    kl_divergence = entropy(obtained_probs, target_probs)\n",
    "    \n",
    "    return kl_divergence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6169da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 6\n",
    "\n",
    "num_layers = 3\n",
    "\n",
    "n_shots = 1e5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
